name: News Scraper Bot

on:
  schedule:
    # Runs every hour
    - cron: '0 * * * *'
  workflow_dispatch: # Allows manual trigger from GitHub UI

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install Dependencies
        run: npm install

      - name: Run Scraper
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
          DAILY_POSTS_EN: 12
          DAILY_POSTS_ES: 5
          AI_REWRITE_ENABLED: true
          CLICKBAIT_LEVEL: medium
          PRIORITY_CATEGORIES: Immigration,ICE,Trump,BreakingNews,Border,Deportation,Politics,Legal
          PRIORITY_STATES: Texas,Florida,NewYork,California,Arizona,Georgia,Pennsylvania,Ohio,Michigan
        run: npm start

      - name: Commit Tracking Data
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/*.json
          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "Update tracking data [skip ci]"
            # Pull latest changes to avoid conflicts, then push
            git pull --rebase origin main || git rebase --abort
            git push origin main
          else
            echo "No changes to commit"
          fi
